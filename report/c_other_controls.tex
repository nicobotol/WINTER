\section{Turbine control considering model's uncertainty}\label{sec:c_other_controls}
The control methods developed so far relay on the knowledge of the system by means of their parameters (structural and environmental) and models. In fact, in the calculation of the gains $K_{opt}$ and $K_{opt,GE}$ considered in the torque reference generation, a single deterministic constant in time value of all the different terms in \autoref{eq:T_G2} and \autoref{eq:K_opt_GE} have been used. In order to take into account possible variabilities of the parameters, for example due to the wrong estimation of some quantities or their ageing, a different approach has to been used. These modifications may occur in different time horizons, ranging from the second in case of blade deformation up to years, as the air density, which is expected to increase of 0.5\% in the next 20 years due to global worming as reported by \cite{en12112038}. \\
To deal with these uncertainty, one possibility is to use model-free methods \textcolor{red}{Mettere una citazione}, such as the extremum seeking, while another is to suppose that the system may evolve following a model within a finite set and then compare the measured system dynamic with the predicted by the model to decide which is the most probable one by means of the so called \acrfull{IMM} estimator \\textcolor{red}{citazione a bar shalom}. In this work, this last method is employed since it can be seen as an extension of the control methods previously analyzed, allowing to identify the variation of one physical parameter in time and provide a value of $K_{opt}$ to be used in the feedback line of the controller.

\textcolor{red}{Scrivere che da ora in poi si considera la presenza di un sensore di misura con una propria incertezza per permettere di usare il KF}

\subsection{Interactive Multiple Model}\label{subsec:IMM}
\cite{Kalman_Filter_and_Its_Application} states that the \textit{Kalman filter is an algorithm that uses a series of data observed over time, which contains noise and other inaccuracies, to estimates unknown variables with more accuracy.} In other words this algorithm uses the model of the dynamic system, the measurement from a sensor and their uncertainties to provide an estimation of the desired quantity better than what would be done by employing the solely measure or model.\\
 A great disadvantage of the \acrfull{KF} is that it is only suitable for linear systems and linear measurement models. To overcome this issues the \acrfull{EKF} is an algorithms that extend the KF concepts in the nonlinear cases. The basic idea behind it is to linearize the nonlinear dynamic around the status of the estimation at the first order of the Taylor expansion, and then apply the same equations of the linear \acrshort{KF}. The \acrfull{UKF} is another approach to solve the non-linearity issues and it is based on the second order Taylor expansion. This method will not be considered in the thesis, and it is cited here only for completeness.\\
In general, all these methods relay on the knowledge of the model of the system which, as said before, it is not always available due to poor identification or changes in time. One possibility to reduce this issue is given by the \acrshort{IMM}. This algorithm firstly runs a parallel bank of $N_j$ filters estimating the same quantity, each of them using a different model of the system and later on weights the filters' output by their likelihood conditioned on the measurement in order to provide the overall estimation of interest. In principle the filters run in parallel may be of any type (e.g. KF, EKF, UKF, or further ones), but the EKF has been adopted here for its simplicity. 

\subsubsection{Steps of the implementation of the IMM}
Here the procedure for implementing the IMM is reported, following the method proposed in \cite{kalman_based_IMM}. In particular the estimation of the quantity is given in 4 subsequently steps named filtering, mode probability updating, state combination and filter interaction. A graphical visualization of the method is given in \autoref{fig:IKK_schema}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\columnwidth]{images/IMM_schema.png}
  \caption{Graphical visualization of a IMM, source \cite{kalman_based_IMM}}
  \label{fig:IKK_schema}
\end{figure}
It is worth nothing that the method proposed here is not strictly related to the wind turbine filed, but it can be applied to all the dynamic systems.

\textit{Adopted notation}\\
\begin{gather}
  \text{State of the \textit{j-th} filter at time k: } x^{(j)}_{k}  \\
  \text{Estimated state of the IMM: } \hat{x}_{k}\\
  \text{Input: } u_{k} \\
  \text{Measure: } y_{k} \\
  \text{Model of the plant: }  x_{k+1} = f(x_k, u_k, \nu_k) \\
  \text{Noise on the dynamic: } \nu_k \sim \mathcal{N}(0, Q) \\ \label{eq:noise_Q}
  \text{Model of the measurement instrument: } y_k = h(x_k, u_k, \varepsilon_k) \\
  \text{Noise on the measurement: } \varepsilon_k \sim \mathcal{N}(0, W)  \\
  \text{Covariance matrix of the process: } Q\\
  \text{Covariance matrix of the measurement: } W \\
  \text{Covariance matrix of the state estimation for the \textit{j-th} filter } P^{(j)}\\
  \text{Linearized model of the plant with respect to the states: } F_k = \frac{\partial f(x_k, u_k, 0)}{\partial x}\\
  \text{Linearized model of the measurement with respect to the states: } H_k = \frac{\partial h(x_k, u_k)}{\partial x}\\
  \text{Linearized model of the noise on the model: } G_k = \frac{\partial f(x_k, u_k, 0)}{\partial \nu}\\
  \text{Mode probability: } \mu^{(j)}\\
  \text{Likelihood of a filter: } \Lambda^{(j)}
\end{gather}
The symbolic expression of the different quantity are reported in the Appendix \autoref{sec:e_symbolic_IMM} for brevity.\\

\begin{enumerate}
\item \textit{Filtering}

The EKF is based on two steps, named prediction and update which will be here presented. The apex (j) stresses the fact that EKF algorithm has to be repeated for each of the $N_j$ filters. It must be remembered that the KF/EKF work under the assumptions that the noises are uncorrelated, zero mean and Gaussian distributed \cite{Kalman_Filter_and_Its_Application}. 

Prediction step: the state dynamic and covariance are propagated based on the model only 
\begin{gather}
  \hat{x}_k^{(j)-} = f(\hat{x}_{k-1}^{(j)+}, u_k, \nu_k)\\
  F_k^{(j)} = \frac{\partial f}{\partial x}(\hat{x}_{k-1}^{(j)+}, u_k, 0)\\
  G_k^{(j)} = \frac{\partial f}{\partial x}(\hat{x}_{k-1}^{(j)+}, u_k, 0)\\
  P_k^{(j)-} = F_k^{(j)} P_{k-1}^{(j)+} \left(F_k^{(j)}\right)^T + G_k^{(j)} Q_k \left(G_k^{(j)}\right)^T
\end{gather}
Update step: the state dynamic and covariance are modified based on a measurement 
\begin{gather}
  \hat{y}_k = h(\hat{x}_k^{(j)-}, u_k, \varepsilon_k)\\
  H_k = \frac{\partial h}{\partial x}(\hat{x}_k^{(j)-}, u_k)\\
  L_k = P_k^- H_k^T (H_k P_k^- H_k^T + R_k)^{-1}\\
  \hat{x}_k^+ = \hat{x}_k^- + L_k (y_k - \hat{y}_k)\\
  P_k^+ = (I - L_k H_k) P_k^-
\end{gather}

\item \textit{Mode probability updating}\\
In this step the mode probabilities are updated from the filter likelihood (i.e. how likely the filter provides a good state estimate from the measurement). This is done assuming that the error residuals are Gaussian distributed.  
\begin{gather}
  \text{Residual: } z_k^{(j)} = y_k - \hat{y}_k^{(j)}\\
  \text{Uncertainty on the residual: }S_k^{(j)} = H_k^{(j)} P_k^{(j)-} (H_k^{(j)})^T + R_k^{(j)}\\
  \text{Likelihood: } \Lambda_k^{(j)} = \frac{1}{\sqrt{2 \pi \lvert S_k^{(j)} \rvert}} \exp{\left(-\frac{1}{2}\left(z_k^{(j)}\right)^T \left(S_k^{(j)}\right)^{-1} z_k^{(j)}\right)}\\
  \mu_k^{(j)+} = \frac{\mu_k^{(j)-}\Lambda_k^{(j)}}{\sum_{i} \mu_k^{(i)-}\Lambda_k^{(i)}}
\end{gather}
In the application presented in \cite{kalman_based_IMM}, the IMM is used only for an estimation of the state. Here, differently, there is also the necessity of identifying the model for closing the control loop, meaning that at each step a value of $\hat{K}_{opt,GE}$ has to be provided and used for generating the reference torque. To do so, two methods have been identified. The first is to assign the value of the model with the highest probability, while the second is to compute the mean of the models' gain weighted by their probabilities. The second approach is here preferred, because it takes into account the information of all the models run in parallel.
\begin{gather}
\hat{K}_{opt,GE,k} = \sum_j \mu_k^{(j)+} K_{opt,GE}^{(j)}
\end{gather}

\item \textit{State combination}\\
The output state of the IMM is computed by combining the state of each filter by the corresponding covariance:
\begin{gather}
  \hat{x}_k^+ = \sum_j \mu_k^{(j)+} \hat{x}_k^{(j)+}\\
  P_k^+ = \sum_j \mu_k^{(j)+} \left(P_k^{(j)+} + \left(\hat{x}_k^+ - \hat{x}_k^{(j)+}\right)\left(\hat{x}_k^+ - \hat{x}_k^{(j)+}\right)^T\right)
\end{gather}

\item \textit{Filter interaction}\\
In this last step, the filter with higher probabilities modify the estimates of the ones with lower probabilities. Each filter is considered as a mode, and the switching process of the modes is modelled by a time-invariant Markov chain. The mode transition probability $\pi_{ik} = \Pi(i, k)$ describes how likely the mode \textit{i} is change to mode \textit{j}. $\Pi \in \mathbb{R}^{N_j \times N_j}$ is the mode transition matrix, and it is a design parameter. In this application it is a symmetric matrix, with $\pi_{ii}=0.99$ and $\pi_{ik}=\pi_{ki}=\frac{1 - 0.99}{N_j} \,\forall \, i\neq k $ as proposed in \cite{kalman_based_IMM}.

\begin{gather}
  \mu_{k+1}^{(j)-} = \sum_i \pi_{ij}\mu_k^{(i)+}\\
  \mu_k^{(i|j)-} = \frac{\pi_{ij}\mu_k^{(i)+}}{\mu_{k+1}^{(j)-}} = \frac{\pi_{ij}\mu_k^{(i)+}}{\sum_i \pi_{ij}\mu_k^{(i)+}}\\
  \tilde{x}_k^{(j)+} = \sum_i \mu_k^{(i|j)-} \hat{x}_k^{(i)+}\\
  \tilde{P}_k^{(j)+} = \sum_i \mu_k^{(i|j)-} \left(P_k^{(i)+} + \left(\tilde{x}_k^{(j)+} - \hat{x}_k^{(i)+}\right)\left(\tilde{x}_k^{(j)+} - \hat{x}_k^{(i)+}\right)^T\right)
\end{gather}
\begin{equation}
  \Pi = 
  \begin{bmatrix}
    \pi_{11} & \dots & \pi_{1j} & \\
    \vdots & \ddots & \\
    \pi_{j1} &  & \ddots \\
     & & & \pi_{N_jN_j}
  \end{bmatrix}
  \in \mathbb{R}^{N_j \times N_j}
\end{equation}
Then the filtering step is repeated, with the mixed state $\tilde{x}_k^{(j)+}$ and covariance $\tilde{P}_k^{(j)+}$ in the prediction.
\end{enumerate}


\subsubsection{Limitations of the study}
Before going on in the description it is important to state some limitation of the proposed study.
\begin{itemize}
  \item The proposed method is intended to adapt the control law according to the modification of the wind turbine parameters. For some of those, the aerodynamical implication are not trivial. For example when the blade deforms, then the entire map of the power coefficient developed in \autoref{subsec:lookup_cp} is no more valid and needs to be recomputed, alongside the optimal TSR and pitch angle. In order to keep the problem simple and focus only on the framework of the solution, only the air density variation is taken into account, since it does not modify the values of the optimal $\lambda$ and $\theta$ but only rescales the cp map. 
  \item The IMM method works \textit{well} when the models run in parallel are different each others. To make the results of the simulation more clear, the changing parameters will be modified more than what would have been done in reality, in order to employ models that are reasonably different each others. A more fine definition of the models in order to track realistic changes of the real systems may be part of a future investigations. 
  \item Ref. \cite{kalman_based_IMM} reports an example of the implementation of the IMM in a WT with only a rotational speed measurement, as the methods previously described in the work. On the other hand when I tried to reproduce the same approach, I found it not working as expected since the estimations of the states were not accurate enough to close the control loop in an effective way. In order to overcome this issue, a wind speed measurement has been added. Nevertheless, results shows the method becomes effective even with a low accuracy measurement, as that may be typically obtained from an anemometer placed in the nacelle. \textcolor{red}{Vedere se si trova una reference} \\
  One may also try to replace the wind speed measurement with others, paying attention to avoid the correlation between them.
\end{itemize} 

\subsubsection{Definition of the boundaries for the variable parameters}
As said before, the IMM requires a-priori definition of the parameters of the models run in each filter. It could be easily understood how the choice of these parameters is crucial for letting the algorithm work properly. In fact if the true model is in the considered set the algorithm will converge to it, otherwise it will move towards the most similar one, that may be \textit{close enough} or not according to the design choice. As said before, here the models are chosen to be reasonably different each others.

\subsubsection{Definition of the uncertainty}
In the EKF equations run in the IMM it is necessary to identify the noise on the process $\nu_k \sim \mathcal{N}(0, Q)$. The definition of Q is again done using the \acrshort{MC} approach, with the same distributions already used in the $K_{opt,GE}$ case. Here the equation for the method is:
\begin{equation}
  \tilde{T}_R=\frac{\frac{1}{2}\tilde{\rho}\pi\tilde{R}^2cp\left(\tilde{\omega}, \tilde{V}_0,\tilde{R}\right)\tilde{V}_0^3}{\tilde{\omega}}
  \label{eq:T_R_distribution}
\end{equation}
where the \textit{tildes} stress the fact that the parameters come from a distribution. The computed variance of the noise is $Q = 2.3715 \cdot 10^{12} \, \mesunt{\square\newton\square\meter}$.

\subsubsection{Filter of the state and the K gain}
In order to reduce the variability of the rotational speed estimations done by the parallel \acrshort{EKF}, the value in the feedback line is filtered using a low pass filter
\begin{equation}
  G(s) = \frac{1}{\frac{1}{25.1}s + 1}
\end{equation}
Also the value of the gain $K$ is low pass filtered with a similar filter
\begin{equation}
  G(s) = \frac{1}{\frac{1}{2.51}s + 1}
\end{equation}

\subsubsection{Results of the IMM} 
The first test done is the comparison between the IMM-based control and the one based on the constant gain for 5 constant WSs between the cut-in and the rated one (4, 6, 8, 10, and 11 $\mesunt{\meter\per\second}$). In particular, for each input wind velocity a couple of simulation has been run, with the same noise, in order to better compare them. \\
In order to compare the control methods, the integral of the powers has been computed. It has been observed that the power in the two cases were quite similar, and so the choice of the time interval to be integrated was important to identify which method provides more energy. The results of teh tests are reported in \autoref{tab:comparison_IMM}. The first colum reports the time from the end of the simulation were the integration started, the second reports the wind speed of the tested case, the third, and fourth the energy extracted from the rotor with the two considered control techniques, while the fifth the error between them. The last three columns report the energy at the electrical output of the generator and the corresponding normalized error. The error has been computed as:
\begin{equation}
  \text{Error} = \frac{E_{IMM}-E_{Const}}{E_{Const}}\cdot 100 \left[-\right]
  \label{eq:energy_error}
\end{equation}

\begin{table}[htb]
  \caption{Comparison of the energy extracted from the resource and at the generator's output for the use of IMM based or fixed gain controllers, and their error}
  \centering
  \begin{tabular}{cc|ccc|ccc}
    \toprule
    % write R above the third and fourth column and GE above the last two
    Integration & & \multicolumn{3}{c|}{Rotor} & \multicolumn{3}{c}{Generator Electrical output}\\
    time & WS & IMM & Const. & Err. & IMM & Const. & Err.\\
    $\mesunt{\second}$ & $\mesunt{\meter\per\second}$ & $\mesunt{\giga\joule}$ &   $\mesunt{\giga\joule}$ & $\left[\%\right]$& $\mesunt{\giga\joule}$ &   $\mesunt{\giga\joule}$ & $\left[\%\right]$ \\
    \midrule
    \input{macro/energy.tex}
  \end{tabular}
  \label{tab:comparison_IMM}
\end{table}

From the numerical values of the error, it can be seen that the difference between the methods are small. This can be explained by observing the time evolution of the K gain, the power, and the rotational speed. In particular, the values of the gains in the IMM control cases are not far from the constant value case (see \autoref{fig:fig_K_IMM} and \autoref{tab:mean_std_IMM} with the error defined as \autoref{eq:K_error}), and so the generator torques are similar.
\begin{equation}
  \text{Error} = \frac{K_{IMM}-K_{GE}}{K_{GE}}\cdot 100 \left[-\right]
  \label{eq:K_error}
\end{equation}
Furthermore, the high rotor inertia filters out the torque fluctuations and stabilizes the rotational speed around a similar value, as could be seen in \autoref{fig:fig_omega_IMM} where the rotor speeds for the two cases are reported alongside the estimation done by each of the filter run in the IMM, and the overall IMM estimation. 

\begin{figure}[htb]
  \centering
  \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/vectorial/2023_10_27_16_20_52omega_IMM.eps}
    \caption{K gains for the simulations with the IMM control}
    \label{fig:fig_K_IMM}
  \end{subfigure}
  \\
  \begin{subfigure}{0.65\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/vectorial/2023_10_28_00_11_27fig_rotor_generator_power_dynamic.eps}
    \caption{Input power from the generator and output power from the electrical generator. }
    \label{fig:fig_power_IMM}
  \end{subfigure}
  \caption{\textcolor{red}{Write an overall caption for the two figures}}
\end{figure}
It could be seen that the generator output power in the case of the IMM control fluctuates whereas the other is constant. This difference is clearly given by the different generator's controller. On the other hand the two rotor power are almost equal, because the rotational speed in the two cases are very close each others. 

\begin{table}[htb]
  \caption{Mean value and standard deviation of the K gains in the simulations using the IMM}
  \centering
  \begin{tabular}{ccccc}
    \toprule
    Avg. time & WS & Mean & Std & Error \\
    $\mesunt{\second}$ & $\mesunt{\meter\per\second}$ & $\mesunt{\newton\meter\square\second}$ & $\mesunt{\newton\meter\square\second}$ & $\left[\%\right]$\\  \midrule
    \input{macro/mean_std_IMM.tex}
  \end{tabular}
  \label{tab:mean_std_IMM}
\end{table}

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.5\columnwidth]{images/vectorial/2023_10_27_16_20_52omega_IMM_9.eps}
  \caption{Comparison between the rotor rotational speed in the IMM and constant gain control cases for a WS of 9 $\mesunt{\meter\per\second}$. The figure shows also the estimation done by each filter run during the IMM and the combined estimation.}
  \label{fig:fig_omega_IMM}
\end{figure}

The effect of the filter on the gain value could be seen in \autoref{fig:filter_K}.
\begin{figure}
  \centering
  \includegraphics[width=0.5\columnwidth]{images/vectorial/2023_10_28_09_38_53fig_K.eps}
  \caption{Value of the gain K obtained from the IMM before and after the application of a low pass filter}
  \label{fig:filter_K}
\end{figure}
